{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aj575bfOTZ_x"
   },
   "source": [
    "# Car detection by YOLO algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSA43dCKTZ_y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import colorsys\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNkXK8bqTZ_2"
   },
   "source": [
    "## 1 - YOLO\n",
    "\n",
    "### 1.1 Model\n",
    "\n",
    "The yolo model takes an input image (shape (416, 416, 3)), after passing through a ConvNet (see below), output a feature vector of shape (13, 13, 5*(80+1+4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMnxWEsSTZ_2",
    "outputId": "923a6239-d3ec-4024-d879-83ebaad5f712"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "yolo_model = tf.keras.models.load_model('model_data/yolov2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xdsUGdUcTZ_6"
   },
   "source": [
    "### 1.2 Reading classes and anchors file as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYgwQGj7TZ_6"
   },
   "outputs": [],
   "source": [
    "with open(\"model_data/coco_classes.txt\") as f:\n",
    "    class_names = [c.strip() for c in f.readlines()]\n",
    "\n",
    "anchors = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "anchors = np.array(anchors).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_uMhubWTZ_-"
   },
   "source": [
    "## 2 - Preprocessing\n",
    "\n",
    "### 2.1 Converting image of any size to size of (416, 416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mp7IHUJoTZ_-"
   },
   "outputs": [],
   "source": [
    "def image_preprocessing(image_file):\n",
    "    image = Image.open(image_file)\n",
    "    image_resized = image.resize((416, 416), Image.ANTIALIAS)\n",
    "    image_data = np.array(image_resized) / 255.\n",
    "    image_data = np.expand_dims(image_data, 0)\n",
    "    return image, image_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31HN7GupTaAA"
   },
   "source": [
    "## 3 - Postprocessing\n",
    "\n",
    "### 3.1 Converting final layer from yolo model to box parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uctuTGvKTaAB"
   },
   "outputs": [],
   "source": [
    "def post_processing(features, anchors, num_classes=80):\n",
    "    \"\"\"\n",
    "    From the original paper:\n",
    "    b_x = sigmoid(f_x) + c_x\n",
    "    b_y = sigmoid(f_y) + c_y\n",
    "    b_w = anchor_w * exp(f_w)\n",
    "    b_h = anchor_h * exp(f_h)\n",
    "    box_prob = sigmoid(f_box_prob)\n",
    "    \n",
    "    Input:\n",
    "    features - final convolutional layer from yolo model, shape of (1, 13, 13, num_anchors*(1+4+80))\n",
    "    anchors - (5, 2)\n",
    "    \n",
    "    Output:\n",
    "    box_probs - (1, 13, 13, num_anchors, 1)\n",
    "    box_sizes - (1, 13, 13, num_anchors, 4), each term in last dim corresponding (y1, x1, y2, x2)\n",
    "    class_probs - (1, 13, 13, num_anchors, 80)\n",
    "    \"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    anchors = tf.constant(anchors, shape=[1, 1, 1, num_anchors, 2], dtype=features.dtype)\n",
    "\n",
    "    dims = tf.shape(features)[1:3]\n",
    "    h, w = dims[0], dims[1]\n",
    "    h_index = tf.reshape(tf.tile(tf.range(h), [w]), [1, h, w, 1, 1])\n",
    "    w_index = tf.transpose(h_index, [0, 2, 1, 3, 4]) # assuming h=w\n",
    "    index = tf.cast(tf.concat([h_index, w_index], axis=-1), features.dtype)\n",
    "    dims = tf.cast(tf.reshape(dims, [1, 1, 1, 1, 2]), features.dtype)\n",
    "    features = tf.reshape(features, [-1, h, w, num_anchors, num_classes+5])\n",
    "\n",
    "    box_xy = (tf.sigmoid(features[..., :2]) + index) / dims # unit: image.size\n",
    "    box_wh = tf.exp(features[..., 2:4]) * anchors / dims # unit: image.size\n",
    "    \n",
    "    # convert center and corner representation\n",
    "    box_mins = box_xy - (box_wh / 2.)\n",
    "    box_maxes = box_xy + (box_wh / 2.)\n",
    "    box_sizes = tf.concat([box_mins[..., 1:2], box_mins[..., 0:1], box_maxes[..., 1:2],box_maxes[..., 0:1]], -1)\n",
    "    \n",
    "    box_probs = tf.sigmoid(features[..., 4:5])\n",
    "    class_probs = tf.nn.softmax(features[..., 5:])\n",
    "    return box_probs, box_sizes, class_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Da0Zhq02TaAD"
   },
   "source": [
    "### 3.2 Filtering boxes that have low scores and implementing non max suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1Y2RriaTaAE"
   },
   "outputs": [],
   "source": [
    "def box_filter_and_nonmax_suppression(box_probs, box_sizes, class_probs, threshold=0.3, max_num_boxes=10):\n",
    "    \"\"\" \n",
    "    Input:\n",
    "    box_probs shape (1, 13, 13, 5, 1)\n",
    "    box_sizes shape (1, 13, 13, 5, 4), each term corresponding to (y1, x1, y2, x2)\n",
    "    class_probs shape (1, 13, 13, 5, 80)\n",
    "    \n",
    "    Output:\n",
    "    scores shape (None,)\n",
    "    box_sizes shape (None, 4)\n",
    "    classes shape (None,)\n",
    "    \"\"\"\n",
    "    box_scores = box_probs * class_probs\n",
    "    scores = tf.reduce_max(box_scores, axis=-1)\n",
    "    classes = tf.argmax(box_scores, axis=-1)\n",
    "    mask = scores >= threshold\n",
    "    box_sizes = tf.boolean_mask(box_sizes, mask)\n",
    "    scores = tf.boolean_mask(scores, mask)\n",
    "    classes = tf.boolean_mask(classes, mask)\n",
    "    \n",
    "    nonmax_indices = tf.image.non_max_suppression(box_sizes, scores, max_output_size=tf.constant(max_num_boxes), iou_threshold=0.5)\n",
    "    box_sizes = tf.gather(box_sizes, nonmax_indices)\n",
    "    scores = tf.gather(scores, nonmax_indices)\n",
    "    classes = tf.gather(classes, nonmax_indices)\n",
    "    \n",
    "    return scores, box_sizes, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g6_rYlWLTaAF"
   },
   "source": [
    "### 3.3 Drawing boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SR5ypY2lTaAH"
   },
   "outputs": [],
   "source": [
    "def draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors):\n",
    "    \n",
    "    w, h = image.size\n",
    "    font = ImageFont.truetype('arial', size=np.ceil(2.5e-2 * h).astype('int32'))\n",
    "    thickness = (w + h) // 400\n",
    "    \n",
    "    for i, n in list(enumerate(out_classes)):\n",
    "        class_prediction = class_names[n]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "        \n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.ceil(top * h).astype('int32'))\n",
    "        left = max(0, np.ceil(left * w).astype('int32'))\n",
    "        bottom = min(image.size[1], np.ceil(bottom * h).astype('int32'))\n",
    "        right = min(image.size[0], np.ceil(right * w).astype('int32'))\n",
    "        \n",
    "        label = '{0:s} {1:.3f}'.format(class_prediction, score)\n",
    "        labelsize = draw.textsize(label, font)\n",
    "        \n",
    "        for i in range(thickness):\n",
    "            draw.rectangle([left+i, top+i, right-i, bottom-i], outline=colors[n])\n",
    "        draw.rectangle([(left, top), (left+labelsize[0], top+labelsize[1])], fill=colors[n])\n",
    "        \n",
    "        draw.text((left+1, top+1), label, fill=(0,0,0), font=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdPqkwiATaAJ"
   },
   "outputs": [],
   "source": [
    "def generate_color(class_names):\n",
    "    n = len(class_names)\n",
    "    hsv_tuples = [(x / n, 1., 1.) for x in range(n)]\n",
    "    rgb_tuples = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0]*255), int(x[1]*255), int(x[2]*255)), rgb_tuples))\n",
    "    random.seed(11100)\n",
    "    random.shuffle(colors)\n",
    "    random.seed(None)\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1YuziSyhTaAL"
   },
   "source": [
    "## 4 Making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V61p56__TaAL"
   },
   "outputs": [],
   "source": [
    "sess = tf.keras.backend.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kAqIorH4TaAP"
   },
   "outputs": [],
   "source": [
    "def prediction(sess, image_file, box_prob_threshold=0.3):\n",
    "    \n",
    "    image, image_data = image_preprocessing(\"images/\" + image_file)\n",
    "    image_shape = [float(image.size[1]), float(image.size[0])]\n",
    "    \n",
    "    box_probs, box_sizes, class_probs = post_processing(yolo_model.output, anchors)\n",
    "    scores, box_sizes, classes = box_filter_and_nonmax_suppression(box_probs, box_sizes, class_probs, box_prob_threshold)\n",
    "    out_scores, out_boxes, out_classes = sess.run([scores, box_sizes, classes], feed_dict={yolo_model.input: image_data, tf.keras.backend.learning_phase(): 0})\n",
    "    \n",
    "    return image, out_scores, out_boxes, out_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yu8uFvf6TaAR"
   },
   "outputs": [],
   "source": [
    "def show_and_save_image(image_file, figsize=(16,16), box_prob_threshold=0.4):\n",
    "    plt.figure(figsize=figsize)\n",
    "    image, out_scores, out_boxes, out_classes = prediction(sess, image_file, box_prob_threshold)\n",
    "    colors = generate_color(class_names)\n",
    "    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    image.save(os.path.join('outputs/', image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qv35rugMTaAX"
   },
   "outputs": [],
   "source": [
    "show_and_save_image('test.jpg', box_prob_threshold=0.4)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PR_project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
